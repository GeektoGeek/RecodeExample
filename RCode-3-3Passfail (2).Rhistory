install.packages("h2o")
library(h2o)
install.packages("data.table")
q()
install.packages("logistf")
library(logistf)
data(sex2)
View(sex2)
summary(sex2)
df<- sex2
summary(df$case)
library(data.table)
install.packages("data.table")
library(data.table)
library(data.table)
data.table(summary$case)
data.table(summary(df$case))
df1<- data.table(summary(df$case))
prop.table(table(df$case))
install.packages("caret")
library(caret)
set.seed(3033)
index <- createDataPartition(y = df$case, p= 0.7, list = FALSE)
training <- train[index,]
testing <- train[-index,]
library(caret)
set.seed(3033)
index <- createDataPartition(y = df$case, p= 0.7, list = FALSE)
training <- df[index,]
testing <- df[-index,]
fit.glm<- glm(case~age+oc+vic+vicl+vis+dia,data=training,family=binomial())
install.packages("pscl")
library(pscl)
pR2(fit.glm)
library(pscl)
pR2(fit.glm)
pR2(fit.glm)
install.packages("pscl")
library(pscl)
library(pscl)
pR2(fit.glm)
pred<- predict(fit.glm,newdata=testing, type='response')
pred<- predict(fit.glm,newdata=testing, type='class')
testing<- cbind(testing,pred)
View(testing)
testing$pred <- ifelse(pred > 0.5, 1,0)
summary(fit.glm)
Accuracy<- 1- (mean(testing$case!= testing$pred))
Accuracy
fit_penalizedLogistic<-logistf(case ~ age+oc+vic+vicl+vis+dia, data=training)
install.packages("logistf")
library(logistf)
fit_penalizedLogistic<-logistf(case ~ age+oc+vic+vicl+vis+dia, data=training)
summary(fit_penalizedLogistic)
pR2(fit_penalizedLogistic)
pred_logispenal<- predict(fit_penalizedLogistic,newdata=testing, type='response')
pred_logispenal<- predict(fit, newdata = testing[1:5, ], type = 'response')
pred_logispenal<- predict(fit_penalizedLogistic, newdata = testing[1:5, ], type = 'response')
install.packages("brglm")
library(brglm)
library(brglm)
pred_logispenal<- predict(fit_penalizedLogistic, newdata = testing[1:5, ], type = 'response')
fit_penalizedLogistic<-brglm(case ~ age+oc+vic+vicl+vis+dia, data=training)
Pred1<- predict(fit_penalizedLogistic, newdata = testing[1:5, ], type = "response")
testing<- cbind(testing,pred1)
testing<- cbind(testing,Pred1)
Pred1<- predict(fit_penalizedLogistic, newdata = testing[1:71, ], type = "response")
testing<- cbind(testing,Pred1)
testing$Pred1 <- ifelse(Pred1 > 0.5, 1,0)
Accuracy1<- 1- (mean(testing$case!= testing$Pred1))
#### How to boot strap a specific mean or median from multiple samples..
meanf<- function(x,i){mean(x[i])}
bootmean<- boot(data=mtcars$mpg, meanf, R=1000)
install.packages("boot")
library(boot)
bootmean<- boot(data=mtcars$mpg, meanf, R=1000)
bootmean
meanf<- function(x,i){mean(x[i])}
bootmean<- boot(data=mtcars$mpg, meanf, R=1000)
bootmean
medianf<- function(x,i){median(x[i])}
bootmedian<- boot(data=mtcars$mpg, medianf,R=1000)
bootmedian
bootCI <- boot.ci(median.boot, conf = .90, type="bca")
bootCI <- boot.ci(bootmedian, conf = .90, type="bca")
bootCI
setwd("~/CodeForAllProjects/R/KnowData_Project")
Data2<- read.csv("Data2.csv", sep=",")
install.packages("caret")
library(caret)
str(Data2)
View(Data2)
Data2$LabelR<- as.factor(Data2$LabelR)
View(Data2)
### Changing the Pass_Fail into logical
summary(Data2$Pass_Fail)
Data2$Pass_FailR<- Data2$Pass_Fail
View(Data2)
Data2$Pass_FailR<- as.logical(Data2$Pass_FailR)
View(Data2)
Data2<- subset(Data2, select=c(1,2,3,4,5))
View(Data2)
Data2$Pass_FailR<- Data2$Pass_Fail
Data2$Pass_FailR<- as.numeric(factor(Data2$Pass_FailR))
View(Data2)
summary(Data2$Pass_FailR)
prop.table(Data2$Pass_FailR)
prop.table(summary(Data2$Pass_FailR))
summary(prop.table((Data2$Pass_FailR)))
Data2$Pass_FailR<- as.logical(Data2$Pass_FailR)
View(Data2)
Data2<- subset(Data2, select=c(1,2,3,4,5))
View(Data2)
View(Data2)
Data2$Pass_FailR<- Data2$Pass_Fail
Data2$Pass_FailR<- as.logical(levels(factor(Data2$Pass_FailR("FALSE", "TRUE"))))
Data2$Pass_FailR<- as.logical(levels(factor(Data2$Pass_FailR))
)
View(Data2)
Data2<- subset(Data2, select=c(1,2,3,4,5))
View(Data2)
Data2$Pass_FailR<- Data2$Pass_Fail
library(data.table)
install.packages("data.table")
library(data.table)
myDT<- data.table(Data2)
myDT <- myDT[, Pass_FailR:= Pass=="true"]
View(myDT)
myDT[, Pass_FailR:= Pass=="true"]
install.packages("dplyr")
library(dplyr)
library(dplyr)
Data2$Pass_FailR <- lapply(Data2$Pass_FailR, as.character)
View(Data2)
str(Data2)
View(Data2)
str(Data2)
summary(Data2)
View(Data2)
Data2<- subset(Data2, select=c(1,2,3,4,5))
View(Data2)
View(Data2)
Data2$Pass_FailR<- Data2$Pass_Fail
View(Data2)
Data2$Pass_FailR <- Data2$Pass_FailR== "True"
View(Data2)
Data2<- subset(Data2, select=c(1,2,3,4,5))
Data2$Pass_FailR<- Data2$Pass_Fail
View(Data2)
Data2$Pass_FailR[Data2$Pass_Fail %in% c("Fail")] <- FALSE
View(Data2)
Data2<- subset(Data2, select=c(1,2,3,4,5))
Data2$Pass_FailR<- Data2$Pass_Fail
View(Data2)
Data2$Pass_FailR<- as.character(Data2$Pass_FailR)
Data2$Pass_FailR<- as.logical(Data2$Pass_FailR)
View(Data2)
str(Data2$Pass_FailR)
summary(Data2$Pass_Fail)
summary(Data2$Pass_FailR)
Data3<- subset(Data2, select=c(1,2,3,4,6))
View(Data3)
View(Data2)
Data3<- subset(Data2, select=c(1,2,3,5,6))
View(Data3)
library(caret)
a <- createDataPartition(Data3$Pass_FailR, p = 0.8, list=FALSE)
training <- Data3[a,]
testing <- Data3[-a,]
View(training)
View(testing)
train_tbl<- training
test_tbl<- testing
rec_obj <- recipe(Pass_FailR ~ ., data = train_tbl) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep(data = train_tbl)
library(recipes)
library(recipes)
rec_obj <- recipe(Pass_FailR ~ ., data = train_tbl) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep(data = train_tbl)
libray(psych)
library(keras)
library(lime)
library(tidyquant)
library(rsample)
library(rsample)
library(recipes)
library(recipes)
library(yardstick)
library(yardstick)
library(corrr)
model_keras <- keras_model_sequential()
model_keras %>%
# First hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu",
input_shape        = ncol(x_train_tbl)) %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Second hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu") %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Output layer
layer_dense(
units              = 1,
kernel_initializer = "uniform",
activation         = "sigmoid") %>%   # Compile ANN
compile(
optimizer = 'adam',
loss      = 'binary_crossentropy',
metrics   = c('accuracy')
)
model_keras
fit_keras <- fit(
object           = model_keras,
x                = as.matrix(x_train_tbl),
y                = y_train_vec,
batch_size       = 50,
epochs           = 35,
validation_split = 0.30
)
Data7<- read.csv("Data3.csv", sep=",")
View(Data7)
Data8 <- subset(Data7, select=c(1,2,3,5,6))
View(Data8)
summary(Data8$Pass_FailR)
index <- createDataPartition(Data8$Pass_FailR, p = 0.8, list=FALSE)
train_tbl <- Data8[index,]
test_tbl<- Data8[-index,]
Data8 <- subset(Data7, select=c(1,2,3,5,6))
summary(Data8$Pass_FailR)
str(Data8)
Data8$LabelR <- as.factor(Data8$LabelR)
str(Data8)
index <- createDataPartition(Data8$Pass_FailR, p = 0.8, list=FALSE)
train_tbl <- Data8[index,]
test_tbl<- Data8[-index,]
rec_obj <- recipe(Pass_FailR ~ ., data = train_tbl) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep(data = train_tbl)
x_train_tbl <- bake(rec_obj, newdata = train_tbl)
x_test_tbl  <- bake(rec_obj, newdata = test_tbl)
y_train_vec <- ifelse(pull(train_tbl, Pass_FailR) == "TRUE", 1, 0)
y_test_vec <- ifelse(pull(test_tbl, FullyFunded) == "TRUE", 1, 0)
y_train_vec <- ifelse(pull(train_tbl, Pass_FailR) == "TRUE", 1, 0)
y_test_vec <- ifelse(pull(test_tbl, Pass_FailR) == "TRUE", 1, 0)
model_keras <- keras_model_sequential()
model_keras %>%
# First hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu",
input_shape        = ncol(x_train_tbl)) %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Second hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu") %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Output layer
layer_dense(
units              = 1,
kernel_initializer = "uniform",
activation         = "sigmoid") %>%   # Compile ANN
compile(
optimizer = 'adam',
loss      = 'binary_crossentropy',
metrics   = c('accuracy')
)
model_keras
fit_keras <- fit(
object           = model_keras,
x                = as.matrix(x_train_tbl),
y                = y_train_vec,
batch_size       = 50,
epochs           = 35,
validation_split = 0.30
)
fit_keras
model_keras
fit_keras <- fit(
object           = model_keras,
x                = as.matrix(x_train_tbl),
y                = y_train_vec,
batch_size       = 50,
epochs           = 50,
validation_split = 0.30
)
fit_keras
model_keras
fit_keras <- fit(
object           = model_keras,
x                = as.matrix(x_train_tbl),
y                = y_train_vec,
batch_size       = 50,
epochs           = 50,
validation_split = 0.20
)
fit_keras
model_keras
fit_keras <- fit(
object           = model_keras,
x                = as.matrix(x_train_tbl),
y                = y_train_vec,
batch_size       = 50,
epochs           = 50,
validation_split = 0.15
)
fit_keras
model_keras
fit_keras <- fit(
object           = model_keras,
x                = as.matrix(x_train_tbl),
y                = y_train_vec,
batch_size       = 50,
epochs           = 50,
validation_split = 0.18
)
fit_keras
model_keras
fit_keras <- fit(
object           = model_keras,
x                = as.matrix(x_train_tbl),
y                = y_train_vec,
batch_size       = 60,
epochs           = 35,
validation_split = 0.20
)
fit_keras
plot(fit_keras) +
theme_tq() +
scale_color_tq() +
scale_fill_tq() +
labs(title = "Deep Learning Training Results")
# Predicted Class
yhat_keras_class_vec <- predict_classes(object = model_keras, x = as.matrix(x_test_tbl)) %>% as.vector()
# Predicted Class Probability
yhat_keras_prob_vec  <- predict_proba(object = model_keras, x = as.matrix(x_test_tbl)) %>% as.vector()
# Format test data and predictions for yardstick metrics
estimates_keras_tbl <- tibble(
truth      = as.factor(y_test_vec) %>% fct_recode(yes = "1", no = "0"),
estimate   = as.factor(yhat_keras_class_vec) %>% fct_recode(yes = "1", no = "0"),
class_prob = yhat_keras_prob_vec
)
View(estimates_keras_tbl)
plot(fit_keras) +
theme_tq() +
scale_color_tq() +
scale_fill_tq() +
labs(title = "Deep Learning Training Results")
# Predicted Class
yhat_keras_class_vec <- predict_classes(object = model_keras, x = as.matrix(x_test_tbl)) %>% as.vector()
# Predicted Class Probability
yhat_keras_prob_vec  <- predict_proba(object = model_keras, x = as.matrix(x_test_tbl)) %>% as.vector()
# Format test data and predictions for yardstick metrics
estimates_keras_tbl <- tibble(
truth      = as.factor(y_test_vec) %>% fct_recode(yes = "1", no = "0"),
estimate   = as.factor(yhat_keras_class_vec) %>% fct_recode(yes = "1", no = "0"),
class_prob = yhat_keras_prob_vec
)
View(estimates_keras_tbl)
estimates_keras_tbl
options(yardstick.event_first = FALSE)
# Confusion Table
estimates_keras_tbl %>% conf_mat(truth, estimate)
# Accuracy
estimates_keras_tbl %>% metrics(truth, estimate)
save.image("~/CodeForAllProjects/R/KnowData_Project/RCode-2-25.RData")
savehistory("~/CodeForAllProjects/R/KnowData_Project/RCode-2-25.Rhistory")
savehistory("~/CodeForAllProjects/R/KnowData_Project/Rcode.Rhistory")
