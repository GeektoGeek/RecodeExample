install.packages("h2o")
library(h2o)
install.packages("data.table")
install.packages("logistf")
library(logistf)
data(sex2)
View(sex2)
summary(sex2)
df<- sex2
summary(df$case)
library(data.table)
install.packages("data.table")
library(data.table)
library(data.table)
data.table(summary$case)
data.table(summary(df$case))
df1<- data.table(summary(df$case))
prop.table(table(df$case))
install.packages("caret")
library(caret)
set.seed(3033)
index <- createDataPartition(y = df$case, p= 0.7, list = FALSE)
training <- train[index,]
testing <- train[-index,]
library(caret)
set.seed(3033)
index <- createDataPartition(y = df$case, p= 0.7, list = FALSE)
training <- df[index,]
testing <- df[-index,]
fit.glm<- glm(case~age+oc+vic+vicl+vis+dia,data=training,family=binomial())
install.packages("pscl")
library(pscl)
pR2(fit.glm)
library(pscl)
pR2(fit.glm)
pR2(fit.glm)
install.packages("pscl")
library(pscl)
library(pscl)
pR2(fit.glm)
pred<- predict(fit.glm,newdata=testing, type='response')
pred<- predict(fit.glm,newdata=testing, type='class')
testing<- cbind(testing,pred)
View(testing)
testing$pred <- ifelse(pred > 0.5, 1,0)
summary(fit.glm)
Accuracy<- 1- (mean(testing$case!= testing$pred))
Accuracy
fit_penalizedLogistic<-logistf(case ~ age+oc+vic+vicl+vis+dia, data=training)
install.packages("logistf")
library(logistf)
fit_penalizedLogistic<-logistf(case ~ age+oc+vic+vicl+vis+dia, data=training)
summary(fit_penalizedLogistic)
pR2(fit_penalizedLogistic)
pred_logispenal<- predict(fit_penalizedLogistic,newdata=testing, type='response')
pred_logispenal<- predict(fit, newdata = testing[1:5, ], type = 'response')
pred_logispenal<- predict(fit_penalizedLogistic, newdata = testing[1:5, ], type = 'response')
install.packages("brglm")
library(brglm)
library(brglm)
pred_logispenal<- predict(fit_penalizedLogistic, newdata = testing[1:5, ], type = 'response')
fit_penalizedLogistic<-brglm(case ~ age+oc+vic+vicl+vis+dia, data=training)
Pred1<- predict(fit_penalizedLogistic, newdata = testing[1:5, ], type = "response")
testing<- cbind(testing,pred1)
testing<- cbind(testing,Pred1)
Pred1<- predict(fit_penalizedLogistic, newdata = testing[1:71, ], type = "response")
testing<- cbind(testing,Pred1)
testing$Pred1 <- ifelse(Pred1 > 0.5, 1,0)
Accuracy1<- 1- (mean(testing$case!= testing$Pred1))

/*

#### How to boot strap a specific mean or median from multiple samples..
meanf<- function(x,i){mean(x[i])}
bootmean<- boot(data=mtcars$mpg, meanf, R=1000)
install.packages("boot")
library(boot)
bootmean<- boot(data=mtcars$mpg, meanf, R=1000)
bootmean
meanf<- function(x,i){mean(x[i])}
bootmean<- boot(data=mtcars$mpg, meanf, R=1000)
bootmean
medianf<- function(x,i){median(x[i])}
bootmedian<- boot(data=mtcars$mpg, medianf,R=1000)
bootmedian
bootCI <- boot.ci(median.boot, conf = .90, type="bca")
bootCI <- boot.ci(bootmedian, conf = .90, type="bca")
bootCI

*/

install.packages("keras")
library(keras)
install_keras()
install_keras()
library(keras)
mnist <- dataset_mnist()
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y
reshape
dim(x_train) <- c(nrow(x_train), 784)
dim(x_test) <- c(nrow(x_test), 784)
# rescale
x_train <- x_train / 255
x_test <- x_test / 255
y_train <- to_categorical(y_train, 10)
y_test <- to_categorical(y_test, 10)
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(784)) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 10, activation = "softmax")
summary(model)
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy")
)
model_fit<- fit(
x_train, y_train,
epochs = 30, batch_size = 128,
validation_split = 0.2
)
history <- model %>% fit(
x_train, y_train,
epochs = 30, batch_size = 128,
validation_split = 0.2
)
plot(history)
model %>% evaluate(x_test, y_test,verbose = 0)
model %>% predict_classes(x_test)

### Seems Keras is working now

setwd("~/CodeForAllProjects/R/Sunlytix")
#### Load the files

SunlytixDF<- read.csv("BoulderCodingChallenge.csv", sep=",")
View(SunlytixDF)
SunDF<- subset(SunlytixDF, select=c(2,3,4,5,6,12,19,20,21,22,23,24,27,28,29,30,31,33,44,45,46))
SunDF$Residence_Addresses_CensusBlockGroup<- as.factor(SunDF$Residence_Addresses_CensusBlockGroup)
SunDF$Has_Solar_Target<- as.factor(SunDF$Has_Solar_Target)
install.packages("caret")
library(caret)
a <- createDataPartition(SunDF$Has_Solar_Target, p = 0.8, list=FALSE)
training <- SunDF[a,]
testing<-   SunDF[-a,]
View(testing)
library(Amelia)
library(mice)
library(ggplot2)
library(lattice)
imp.train_raw <- mice(training, m=1, method='cart', printFlag=FALSE)
train_complete <- complete(imp.train_raw)
sum(sapply(train_complete, function(x) { sum(is.na(x)) }))
table(train_complete$Has_Solar_Target)
imp.test_raw <- mice(testing, m=1, method='cart', printFlag=FALSE)
test_complete <- complete(imp.test_raw)
sum(sapply(test_complete, function(x) { sum(is.na(x)) }))
train<- train_complete
test<- test_complete
libray(psych)
library(keras)
library(lime)
library(tidyquant)
library(rsample)
library(rsample)
library(recipes)
library(recipes)
library(yardstick)
library(yardstick)
library(corrr)
library(plyr)
train_tbl<- train
test_tbl<- test
rec_obj <- recipe(Has_Solar_Target ~ ., data = train_tbl) %>%
step_dummy(all_nominal(), -Has_Solar_Target,-Zip) %>%
step_center(all_predictors(), -Has_Solar_Target,-Zip) %>%
step_scale(all_predictors(), -Has_Solar_Target,-Zip) %>%
prep(data = train_tbl)
x_train_tbl <- bake(rec_obj, newdata = train_tbl)
x_test_tbl  <- bake(rec_obj, newdata = test_tbl)
y_train_vec <- train_tbl$Has_Solar_Target
y_test_vec <- test_tbl$Has_Solar_Target
model_keras <- keras_model_sequential()
View(x_train_tbl)

model_keras %>%
# First hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu",
input_shape        = ncol(x_train_tbl,-Zip)) %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Second hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu") %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Output layer
layer_dense(
units              = 1,
kernel_initializer = "uniform",
activation         = "sigmoid") %>%   # Compile ANN
compile(
optimizer = 'adam',
loss      = 'binary_crossentropy',
metrics   = c('accuracy')
)

model_keras %>%
# First hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu",
input_shape        = ncol(x_train_tbl,-c("Zip")) %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Second hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu") %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Output layer
layer_dense(
units              = 1,
kernel_initializer = "uniform",
activation         = "sigmoid") %>%   # Compile ANN
compile(
optimizer = 'adam',
loss      = 'binary_crossentropy',
metrics   = c('accuracy')
)
)

model_keras %>%
# First hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu",
input_shape        = ncol(x_train_tbl) %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Second hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu") %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Output layer
layer_dense(
units              = 1,
kernel_initializer = "uniform",
activation         = "sigmoid") %>%   # Compile ANN
compile(
optimizer = 'adam',
loss      = 'binary_crossentropy',
metrics   = c('accuracy')
)
)
model_keras %>%
# First hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu",
input_shape        = ncol(x_train_tbl)) %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Second hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu") %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Output layer
layer_dense(
units              = 1,
kernel_initializer = "uniform",
activation         = "sigmoid") %>%   # Compile ANN
compile(
optimizer = 'adam',
loss      = 'binary_crossentropy',
metrics   = c('accuracy')
)
fit_keras <- fit(
object           = model_keras,
x                = as.matrix(x_train_tbl,-c("Zip")),
y                = y_train_vec,
batch_size       = 60,
epochs           = 50,
validation_split = 0.20
)
fit_keras <- fit(
object           = model_keras,
x                = as.matrix(x_train_tbl),
y                = y_train_vec,
batch_size       = 60,
epochs           = 50,
validation_split = 0.20
)
fit_keras
plot(fit_keras) +
theme_tq() +
scale_color_tq() +
scale_fill_tq() +
labs(title = "Deep Learning Training Results")
yhat_keras_class_vec <- predict_classes(object = model_keras, x = as.matrix(x_test_tbl)) %>% as.vector()
yhat_keras_prob_vec  <- predict_proba(object = model_keras, x = as.matrix(x_test_tbl)) %>% as.vector()
View(yhat_keras_prob_vec)
yhat_keras_prob_vec  <- predict_proba(object = model_keras, x = as.matrix(x_test_tbl))
View(x_test_tbl)

x_tbl_train1<- x_tbl_train[,-1]
x_train_tbl1<- x_train_tbl[,-1]
View(x_train_tbl1)
x_test_tbl1<- x_test_tbl[,-1]

model_keras1 %>%
# First hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu",
input_shape        = ncol(x_train_tbl1)) %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Second hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu") %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Output layer
layer_dense(
units              = 1,
kernel_initializer = "uniform",
activation         = "sigmoid") %>%   # Compile ANN
compile(
optimizer = 'adam',
loss      = 'binary_crossentropy',
metrics   = c('accuracy')
)
model_keras1 <- keras_model_sequential()
model_keras1 %>%
# First hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu",
input_shape        = ncol(x_train_tbl1)) %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Second hidden layer
layer_dense(
units              = 16,
kernel_initializer = "uniform",
activation         = "relu") %>%
# Dropout to prevent overfitting
layer_dropout(rate = 0.1) %>%
# Output layer
layer_dense(
units              = 1,
kernel_initializer = "uniform",
activation         = "sigmoid") %>%   # Compile ANN
compile(
optimizer = 'adam',
loss      = 'binary_crossentropy',
metrics   = c('accuracy')
)
model_keras1
fit_keras1 <- fit(
object           = model_keras1,
x                = as.matrix(x_train_tbl1),
y                = y_train_vec,
batch_size       = 60,
epochs           = 50,
validation_split = 0.20
)
fit_keras1
fit_keras1 <- fit(
object           = model_keras1,
x                = as.matrix(x_train_tbl1),
y                = y_train_vec,
batch_size       = 60,
epochs           = 80,
validation_split = 0.25
)
fit_keras1 <- fit(
object           = model_keras1,
x                = as.matrix(x_train_tbl1),
y                = y_train_vec,
batch_size       = 60,
epochs           = 30,
validation_split = 0.15
)
set.seed(1232)
fit_keras1 <- fit(
object           = model_keras1,
x                = as.matrix(x_train_tbl1),
y                = y_train_vec,
batch_size       = 60,
epochs           = 50,
validation_split = 0.20
)
fit_keras1
model_keras1
yhat_keras_class_vec1 <- predict_classes(object = model_keras1, x = as.matrix(x_test_tbl1))
yhat_keras_prob_vec1  <- predict_proba(object = model_keras1, x = as.matrix(x_test_tbl1))
View(yhat_keras_prob_vec1)
View(yhat_keras_prob_vec1)
View(yhat_keras_prob_vec1)
View(yhat_keras_class_vec1)
View(yhat_keras_class_vec1)
x_test_tbl1= cbind(x_test_tbl1,yhat_keras_class_vec1)
View(x_test_tbl1)
savehistory("~/CodeForAllProjects/R/Sunlytix/Code-4-1.Rhistory")
