> setwd("H:/Analysis/CloudOne11-18")
> Test <- read.csv("sales_db.csv", sep=",")
> View(Test)
> install.packages("sqldf")
> library("sqldf")
> install.packages("data.table")
> Zip_count<- sqldf("select count(*) as zip_count, zip from Test group by zip order by zip_count desc")

> # Lets look into trade-in vehicle -Make is equal to Vehicle-Make
> trade_makecount<- sqldf("select trade_make, trade_year, trade_model, make, model, year, sale_type,zip from Test1 where trade_make=make group by zip, trade_make")
> write.csv(trade_makecount[,1:8], "trade_makecount.csv", row.names = FALSE)
> # Rolling it a level-up for Trade-Make count
> trade_makecount1<- sqldf("select count(*) as trade_count, trade_make from trade_makecount group by trade_make order by trade_count desc")
> Vehicle_type_count<- sqldf("select count(distinct(vehicle_type)), vehicle_type from Test1 group by vehicle_type, zip")
> View(Vehicle_type_count)
> Vehicle_type_count<- sqldf("select count(distinct(vehicle_type)), vehicle_type from Test1 group by vehicle_type")
> Vehicle_type_count<- sqldf("select count(vehicle_type), vehicle_type from Test1 group by vehicle_type")
> View(Vehicle_type_count)
> trade_in_notsamebrand<- sqldf("select * from Test1 where trade_make!=make group by trade_make,zip order by zip desc")
> View(trade_in_notsamebrand)
> View(trade_in_notsamebrand)
> write.csv(trade_in_notsamebrand[,1:2], "trade_in_notsamebrand.csv", row.names = FALSE)
> View(trade_in_notsamebrand)
> write.csv(trade_in_notsamebrand[,1:15], "trade_in_notsamebrand.csv", row.names = FALSE)

# This is group by zip_code
> selec_make<- sqldf("SELECT make, model, GROUP_CONCAT(zip) AS Zipcodes FROM Test1 group by zip")

# This is group by make
> selec_make<- sqldf("SELECT zip, GROUP_CONCAT(make) as Make, GROUP_CONCAT(model) as Model FROM Test1 group by zip")
> write.csv(selec_make[,1:15], "selec_make.csv", row.names = FALSE)

## Recoding make variable
Make		Coded Values
Audi		1
BMW		2
Chevrolet	3
Dodge		4
Ford		5
GMC		6
Honda		7
Hyundai		8
Jeep		9
Kia		10
Mazda		11
Mitsubushi	12
Nissan		13
Porsche		14
Smart		15
Subura		16
Toyota		17
Volkswagon	18
Buick		19
Cadillac	20
Chrysler	21
Genesis		22
Infiniti	23
Lexus		24
Lincoln		25
Mercedes-Benz	26
Volvo		27
Saturn		28
Subaru		29
Others 		30

Data2$makeR<- Data$make
### Changing it to upper
> Data2$makeR<- toupper(Data2$makeR)

> Data2$makeR = ifelse(Data2$makeR %in% c("AUDI"),1, ifelse(Data2$makeR %in% c("BMW"),2, ifelse(Data2$makeR %in% c("CHEVROLET"),3, ifelse(Data2$makeR %in% c("DODGE"),4, ifelse(Data2$makeR %in% c("FORD"),5, ifelse(Data2$makeR %in% c("GMC"),6, ifelse(Data2$makeR %in% c("HONDA"),7, ifelse(Data2$makeR %in% c("HYUNDAI"),8, ifelse(Data2$makeR %in% c("JEEP"),9, ifelse(Data2$makeR %in% c("KIA"),10, ifelse(Data2$makeR %in% c("MAZDA"),11, ifelse(Data2$makeR %in% c("MITSUBISHI"),12, ifelse(Data2$makeR %in% c("NISSAN"),13, ifelse(Data2$makeR %in% c("PORSCHE"),14, ifelse(Data2$makeR %in% c("SMART"),15, ifelse(Data2$makeR %in% c("SUBARU"),16, ifelse(Data2$makeR %in% c("TOYOTA"),17, ifelse(Data2$makeR %in% c("VOLKSWAGON"),18, ifelse(Data2$makeR %in% c("BUICK"), 19,ifelse(Data2$makeR %in% c("CADILLAC"),20, ifelse(Data2$makeR %in% c("CHRYSLER"),21, ifelse(Data2$makeR %in% c("GENESIS"),22, ifelse(Data2$makeR %in% c("INFINITY"), 23,ifelse(Data2$makeR %in% c("LEXUS"),24, ifelse(Data2$makeR %in% c("LINCOLN"),25, ifelse(Data2$makeR %in% c("MERCEDES-BENZ"),26, ifelse(Data2$makeR %in% c("VOLVO"),27, ifelse(Data2$makeR %in% c("SATURN"),28, ifelse(Data2$makeR %in% c("SUBARU"),29,30)))))))))))))))))))))))))))))
makeR_count<- sqldf("select count(makeR), makeR from Data2 group by makeR")

> Data2$makeR<- as.factor(Data2$makeR)
write.csv(makeR_count[,1:2], "makeR_count.csv", row.names = FALSE)

> ## Let's count all the unique zip and create a ID variable based on zip codes
>  zip_count<-sqldf("select count(zip) as zip_count, zip from Data2 group by zip order by zip desc")
>### Create an id column in the Zip_count and import it to R environment and run a join to append with the original data-set
> Zip_CountM <- read.csv("Zip_count.csv", sep=",")
> Com<- sqldf("select a.*, b.Zip_id from Data2 a left join Zip_CountM b on a.zip=b.zip")
> View(Com)
> ComR<- sqldf("select makeR1,Zip_id, makeR, zip, max(age) as max_age, min(age) as min_age, avg(age) as avg_age, max(term) as max_term, min(term) as min_term, avg(term) as avg_term, count(term) as count_term, sum(term) as sum_term, avg(amount_financed) as avg_amtfin, max(amount_financed) as max_amt_fin, min(amount_financed) as min_amt_fin, sum(amount_financed) as sum_amtfin, count(amount_financed) as cnt_amtfin, max(apr) as max_apr, min(apr) as min_apr, avg(apr) as avg_apr, count(apr) as cnt_apr, sum(apr) as sum_apr from Com group by zip, makeR order by makeR1 desc")
> ComR$zip<-as.factor(ComR$Zip_id)
> h2o.removeAll()
[1] 0

> h2o.init(ip="localhost", port=54321, max_mem_size="1250m")
>### if you receive out of memeory errors, it is probably wise to use the following:
> localH2O <- h2o.init(ip='localhost', nthreads=-1)


R is connected to the H2O cluster: 
    H2O cluster uptime:         9 minutes 28 seconds 
    H2O cluster version:        3.14.0.3 
    H2O cluster version age:    2 months and 5 days  
    H2O cluster name:           H2O_started_from_R_dsarkar_xdv250 
    H2O cluster total nodes:    1 
    H2O cluster total memory:   1.09 GB 
    H2O cluster total cores:    4 
    H2O cluster allowed cores:  4 
    H2O cluster healthy:        TRUE 
    H2O Connection ip:          localhost 
    H2O Connection port:        54321 
    H2O Connection proxy:       NA 
    H2O Internal Security:      FALSE 
    H2O API Extensions:         Algos, AutoML, Core V3, Core V4 
    R Version:                  R version 3.4.1 (2017-06-30) 

> ComR$Zip<- as.factor(ComR$Zip)
> ComR$Zip_id<- as.factor(ComR$Zip_id)
> ComRh2o<- as.h2o(ComR)
> splits<- h2o.splitFrame(ComRh2o, c(0.6,0.2), seed=1234)
> train<- h2o.assign(splits[[1]],"train.hex")
> valid<- h2o.assign(splits[[2]],"valid.hex")
> test<-  h2o.assign(splits[[3]],"test.hex")
library("randomForest")
> rf1<- h2o.randomForest(training_frame = train, validation_frame = valid, x=4:22,y=3,model_id= "rf_covType_v1", ntrees=75, stopping_rounds = 2, score_each_iteration = T,seed=100000)
> summary(rf1)
> rf1@model$validation_metrics
> h2o.hit_ratio_table(rf1,valid=T)[1,2]
Error in names(v) <- v_names : 
  'names' attribute [1] must be the same length as the vector [0]
### This means it has missing values

> h2o.performance(rf1)

finalRf_predictions<-h2o.predict(object = rf1, newdata = test)

summary(finalRf_predictions)

plot(rf1)

### Converting some of the H2o objects to R objects
test1<- as.data.frame(test)
View(test1)

finalRf_predictions1<- as.data.frame(finalRf_predictions)
View(finalRf_predictions1)

### Joining the predicted output (i.e. column) in the test with the orginal data
finalRf_predictions1<-as.data.frame(h2o.predict(object = rf1, newdata = test))
dat <- cbind(test1,finalRf_predictions1$predict)


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> ComR$Zip_id<- as.factor(ComR$Zip_id)
> ComR$makeR<-  as.factor(ComR$makeR)
> ComRh2o<- as.h2o(ComR)
  |==================================================================================================================================| 100%
> splits<- h2o.splitFrame(ComRh2o, c(0.6,0.2), seed=1234)
> train<- h2o.assign(splits[[1]],"train.hex")
> valid<- h2o.assign(splits[[2]],"valid.hex")
> test<-  h2o.assign(splits[[3]],"test.hex")
> y2 <- "makeR"
> x2 <- setdiff(names(ComRh2o), c(y2, "zip","makeR1")) 
> rf1<- h2o.randomForest(training_frame = train, validation_frame = valid, x=x2,y=y2,model_id= "rf_covType_v1", ntrees=75, stopping_rounds = 2, score_each_iteration = T,seed=100000)
> summary(rf1)
> rf1@model$validation_metrics
> h2o.performance(rf1)

finalRf_predictions<-h2o.predict(object = rf1, newdata = test)

summary(finalRf_predictions)

plot(rf1)

### Converting some of the H2o objects to R objects
test1<- as.data.frame(test)
View(test1)

finalRf_predictions1<- as.data.frame(finalRf_predictions)
View(finalRf_predictions1)

### Joining the predicted output (i.e. column) in the test with the orginal data
finalRf_predictions1<-as.data.frame(h2o.predict(object = rf1, newdata = test))
dat <- cbind(test1,finalRf_predictions1$predict)

#### The only problem is here the accuracy of Random Forest in extremely low..only 21%

### Try Gradient Boostingin R 


gbm1<- h2o.gbm(training_frame = train, validation_frame = valid, x=x2,y=y2,model_id= "gbm_covType_v1", ntrees=75, stopping_rounds = 2, score_each_iteration = T,seed=100000)
> gbm1
Model Details:
==============

H2OMultinomialModel: gbm
Model ID:  gbm_covType_v1 
Model Summary: 
  number_of_trees number_of_internal_trees model_size_in_bytes min_depth max_depth mean_depth min_leaves max_leaves mean_leaves
1              45                     1260              628144         5         5    5.00000          8         32    29.83968


H2OMultinomialMetrics: gbm
** Reported on training data. **

Training Set Metrics: 
=====================

Extract training frame with `h2o.getFrame("train.hex")`
MSE: (Extract with `h2o.mse`) 0.7589606
RMSE: (Extract with `h2o.rmse`) 0.8711835
Logloss: (Extract with `h2o.logloss`) 2.391431
Mean Per-Class Error: 0.6285028
Confusion Matrix: Extract with `h2o.confusionMatrix(<model>,train = TRUE)`)
=========================================================================
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class
     1   10  11  12   13 14 15  16  17 18 19  2 20  21 22 23 24 25  26 27  28   3  30   4   5   6   7   8   9  Error               Rate
1  559   17  57   9   33 12  3  77 145  0  3 69 18  15  3  0 77 13 126 14  63  85 110  64 118 112 155  74  78 0.7349 =    1,550 / 2,109
10   4 2387 150  84  363  0  8 163 371  0 37 15 20 133  0  0 41 12  19 19 148 378 309 365 339  56 381 641 208 0.6411 =    4,264 / 6,651
11   2  288 982  43  184  0  6 167 290  0 21  6 15  67  0  0 36 19  15 14 185 170 143 155 125  42 516 418 132 0.7570 =    3,059 / 4,041
12   3  142 129 649  105  0  7  47  99  0 19  7  5  38  0  0 24 15  12 11 184 121  37 137  76  27 149 261  67 0.7263 =    1,722 / 2,371
13  11  502 156  78 2108  1  8 140 478  0 35 25 15 127  4  0 43 17  35 16 139 518 677 443 533 112 508 614 305 0.7244 =    5,540 / 7,648

---
         1   10   11   12   13  14  15   16   17 18   19    2  20   21  22 23   24  25   26  27   28     3    30    4     5    6     7    8
5       19  360  142   50  399   4   5  136  477  0   33   64  34   79   1  0   92  19   80  11  153   785  1260  386  3724  232   453  392
6       62  149   77   23  116  11   6   99  321  0   85   90  38   50   1  0   78  22  137  18   96   598   602  287   444 1154   269  157
7        4  264  171   36  316   0   5  224  603  0   46   39  15   66   1  0   60  12   39   7  180   382   551  192   342   89  2541  495
8        9  553  166   73  405   0   3  166  489  0   37   28  22  117   7  0   31  15   22  11  138   291   358  310   295   61   586 2003
9       18  352  117   46  304   3   4  133  368  0   15   33  21  117   4  0   82  13   59  10  122   524   755  477   650  247   353  333
Totals 954 7657 3617 1593 6955 366 255 3882 9156  2 1170 1835 948 2238 131  0 2851 826 2548 635 3792 10671 13493 6733 11228 4034 10286 8392
          9  Error               Rate
5       412 0.6201 =    6,078 / 9,802
6       387 0.7854 =    4,223 / 5,377
7       199 0.6306 =    4,338 / 6,879
8       151 0.6844 =    4,344 / 6,347
9      1637 0.7592 =    5,160 / 6,797
Totals 6589 0.6959 = 85,486 / 122,837

Hit Ratio Table: Extract with `h2o.hit_ratio_table(<model>,train = TRUE)`
=======================================================================
Top-10 Hit Ratios: 
    k hit_ratio
1   1  0.304070
2   2  0.433184
3   3  0.523653
4   4  0.595374
5   5  0.652157
6   6  0.700416
7   7  0.742114
8   8  0.777388
9   9  0.808706
10 10  0.836922


H2OMultinomialMetrics: gbm
** Reported on validation data. **

Validation Set Metrics: 
=====================

Extract validation frame with `h2o.getFrame("valid.hex")`
MSE: (Extract with `h2o.mse`) 0.8029589
RMSE: (Extract with `h2o.rmse`) 0.8960798
Logloss: (Extract with `h2o.logloss`) 2.6205
Mean Per-Class Error: 0.7821931
Confusion Matrix: Extract with `h2o.confusionMatrix(<model>,valid = TRUE)`)
=========================================================================
Confusion Matrix: Row labels: Actual class; Column labels: Predicted class
     1  10  11  12  13 14 15 16  17 18 19  2 20 21 22 23 24 25 26 27 28   3  30   4   5  6   7   8   9  Error              Rate
1  145   8  12   4  22 20  0 29  65  0  1 16  2  9  1  0 26  4 77 10 19  27  23  17  40 52  50  23  32 0.8025 =       589 / 734
10   1 626  52  27 120  0  1 63 129  0 14  8  8 38  1  0 11  9 13  5 45 113 115 136 131 19 145 235  76 0.7076 =   1,515 / 2,141
11   1 133 171  19  74  0  2 71 112  0 14  5  1 26  0  0  8  4  3  7 75  61  38  72  46 15 200 164  51 0.8755 =   1,202 / 1,373
12   1  57  54 103  44  0  2 21  28  0  4  4  2 29  0  0  5  4  4  4 80  49  19  49  23 10  59  98  35 0.8693 =       685 / 788
13   1 198  74  26 384  2  3 61 172  0 13 15 10 57  1  0 11  5 15  2 46 225 274 168 226 46 219 210 120 0.8514 =   2,200 / 2,584

---
         1   10   11  12   13  14 15   16   17 18  19   2  20  21 22 23  24  25  26  27   28    3   30    4    5    6    7    8    9  Error
5        9  142   46  24  146   3  1   49  180  0  20  20  12  31  0  0  35   9  39   2   67  288  520  144  912   97  147  128  152 0.7170
6       13   50   27  11   48   5  3   32  113  0  37  30  19  25  0  0  22   9  58  12   27  229  219   88  154  250   92   61  164 0.8610
7        1   88   61  19  119   0  1   81  234  0  11  12   5  34  0  0  15   8   9   0   63  143  208   86  132   39  689  154   68 0.6978
8        4  213   47  29  171   0  3   51  151  0  14   7   5  45  2  0  13   4   6   3   44  110  159   96  113   23  207  470   51 0.7697
9        6  124   33  13  105   0  2   47  136  0  12  10   8  45  1  0  28   5  26   1   35  177  299  201  247  102  123  117  327 0.8534
Totals 307 2570 1122 462 2258 126 60 1270 3081  0 347 583 275 716 26  0 847 202 939 150 1272 3453 4788 2310 3783 1425 3543 2763 2198 0.7911
                    Rate
5      =   2,311 / 3,223
6      =   1,548 / 1,798
7      =   1,591 / 2,280
8      =   1,571 / 2,041
9      =   1,903 / 2,230
Totals = 32,339 / 40,876

Hit Ratio Table: Extract with `h2o.hit_ratio_table(<model>,valid = TRUE)`
=======================================================================
Top-10 Hit Ratios: 
    k hit_ratio
1   1  0.208851
2   2  0.330194
3   3  0.423305
4   4  0.499095
5   5  0.562873
6   6  0.619606
7   7  0.669708
8   8  0.711346
9   9  0.747945
10 10  0.781755

> finalgbm_predictions1<-as.data.frame(h2o.predict(object = gbm1, newdata = test))

> dat1 <- cbind(test1,finalgbm_predictions1)


#### Rolling up Make w.r.r Zip

> #### Restart this again
Level1<- sqldf("SELECT zip, upper(GROUP_CONCAT(make)) as MakeConcat, upper(GROUP_CONCAT(model)) as ModelConcat FROM Test1 group by zip")
### This level is optional
Level_optional <- sqldf("select zip, MakeConcat, length(MakeConcat)- length(replace(MakeConcat, ',', '')) + 1 as Makecount from Level1")
### Keep a copy of Level1
> Level2<- Level1
> s <- strsplit(Level2$MakeConcat, split = ",")
> Level3 <- data.frame(zip = rep(Level2$zip, sapply(s, length)), MakeConcat = unlist(s))
> ## Now data is structured in a different way, i.e., for each zip we will have one make per column
Zip MakeConcat
2   Mazda
2   Toyota
2   Mitshubishi
3   Honda
3   Toyota
3   VolksWagen
3   Toyota

> View(Level3)
> Use this data-structure to summarize this based on Make

> L<- sqldf("select zip, count(makeConcat) as count1, MakeConcat from Level3 group by zip, MakeConcat order by zip desc")

### Copy the previous data in a new table
> mydf<- L


> View(Level4)
>####  Now you have the structure you just need to pick the the top three values per zip based on count

> Arrange the data in the deacresing order..# of rows should be same as previous step
> mydf <- mydf[order(mydf$count1, mydf$zip, decreasing = TRUE),] 
> mydf_two<- mydf[ave(mydf$count, mydf$zip, FUN = seq_along) <= 3,]
> Final<- sqldf("SELECT zip, upper(GROUP_CONCAT(MakeConcat)) as MakeConcat FROM mydf_two group by zip")

#### Repeat the same exercise with Model
> D1 <- strsplit(BB2$ModelConcat, split = ",")
> View(BB2)
> D2<- data.frame(zip = rep(BB2$zip, sapply(D1, length)), ModelConcat = unlist(D1))
> View(D2)
> D3<- sqldf("select zip, count(ModelConcat) as count2, ModelConcat from D2 group by zip, ModelConcat order by zip desc")
> View(D3)
> D4 <- mydf[order(D3$count2, D3$zip, decreasing = TRUE),] 
> D4 <- D3[order(D3$count2, D3$zip, decreasing = TRUE),] 
> D4_x<- D4[ave(D4$count, D4$zip, FUN = seq_along) <= 3,]
> View(D4_x)
> FinalModel<- sqldf("SELECT zip, upper(GROUP_CONCAT(ModelConcat)) as ModelConcat FROM D4_x group by zip")
